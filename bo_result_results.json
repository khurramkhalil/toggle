{
  "optimization_summary": {
    "model_name": "gpt2",
    "num_iterations": 30,
    "exploration_weight": 0.2,
    "optimization_time": 552.0175631046295,
    "best_stl_score": -0.803783999213809,
    "best_model_size": 111.74533943457025,
    "best_stl_satisfied": false,
    "best_metrics": {
      "coherence": -0.5842046737670898,
      "attention": -0.05040346458554268,
      "context": 0.14913110435009003,
      "factual": -0.7579973951238864
    },
    "best_robustness": {
      "coherence": -0.5920534133911133,
      "attention": -0.114513099193573,
      "context": 0.13439613580703735,
      "factual": -0.803783999213809
    },
    "optimization_history": {
      "iterations": 32,
      "obj_values": [
        -86.59721808855718,
        -87.01388475522386,
        -84.16985069734393,
        -83.85552492502855,
        -84.40857756276115,
        -84.24002091387217,
        -85.340058054742,
        -84.42826128254914,
        -84.6173858244235,
        -85.51307862221087,
        -85.34999585676269,
        -85.19106345283146,
        -84.8437430027648,
        -85.30037885008757,
        -93.046875,
        -85.09228447399019,
        -84.45974739150695,
        -84.89278452156596,
        -83.84761617723204,
        -83.57340659353372,
        -85.05820167437683,
        -84.9620265458617,
        -84.77939596526517,
        -82.87149162735712,
        -84.40035181710107,
        -84.56712158640309,
        -85.23139812730798,
        -83.193030309938,
        -83.19298086907867,
        -84.81346040713433,
        -84.10564682941137,
        -85.13330910367753
      ]
    }
  },
  "best_results": {
    "metrics": {
      "coherence": -0.5842046737670898,
      "attention": -0.05040346458554268,
      "context": 0.14913110435009003,
      "factual": -0.7579973951238864
    },
    "robustness": {
      "coherence": -0.5920534133911133,
      "attention": -0.114513099193573,
      "context": 0.13439613580703735,
      "factual": -0.803783999213809
    },
    "stl_score": -0.803783999213809,
    "stl_satisfied": false,
    "model_size": 111.74533943457025,
    "inference_time": 0.006257963180541992,
    "config": {
      "layer_0": {
        "attn.c_attn": {
          "bits": 3,
          "pruning": 0.09833809737793138
        },
        "attn.c_proj": {
          "bits": 8,
          "pruning": 0.09200865176363829
        },
        "mlp.c_fc": {
          "bits": 6,
          "pruning": 0.2728653745220759
        },
        "mlp.c_proj": {
          "bits": 4,
          "pruning": 0.41863983717310277
        }
      },
      "layer_1": {
        "attn.c_attn": {
          "bits": 3,
          "pruning": 0.06744858475417298
        },
        "attn.c_proj": {
          "bits": 6,
          "pruning": 0.10800389010241156
        },
        "mlp.c_fc": {
          "bits": 6,
          "pruning": 0.1413602650434905
        },
        "mlp.c_proj": {
          "bits": 4,
          "pruning": 0.20759909553085062
        }
      },
      "layer_2": {
        "attn.c_attn": {
          "bits": 4,
          "pruning": 0.13060279759829563
        },
        "attn.c_proj": {
          "bits": 4,
          "pruning": 0.08000228770824681
        },
        "mlp.c_fc": {
          "bits": 4,
          "pruning": 0.2831698959983899
        },
        "mlp.c_proj": {
          "bits": 2,
          "pruning": 0.22449343374621747
        }
      },
      "layer_3": {
        "attn.c_attn": {
          "bits": 3,
          "pruning": 0.18405286609032406
        },
        "attn.c_proj": {
          "bits": 4,
          "pruning": 0.188888073029943
        },
        "mlp.c_fc": {
          "bits": 6,
          "pruning": 0.043792725422499665
        },
        "mlp.c_proj": {
          "bits": 3,
          "pruning": 0.16877293531605692
        }
      },
      "layer_4": {
        "attn.c_attn": {
          "bits": 10,
          "pruning": 0.10029657902165759
        },
        "attn.c_proj": {
          "bits": 3,
          "pruning": 0.076187588047053
        },
        "mlp.c_fc": {
          "bits": 3,
          "pruning": 0.09987712858516436
        },
        "mlp.c_proj": {
          "bits": 6,
          "pruning": 0.02657153675242936
        }
      },
      "layer_5": {
        "attn.c_attn": {
          "bits": 4,
          "pruning": 0.13464038456179345
        },
        "attn.c_proj": {
          "bits": 6,
          "pruning": 0.03648165079179787
        },
        "mlp.c_fc": {
          "bits": 6,
          "pruning": 0.09351257310968035
        },
        "mlp.c_proj": {
          "bits": 3,
          "pruning": 0.13213184730787383
        }
      },
      "layer_6": {
        "attn.c_attn": {
          "bits": 2,
          "pruning": 0.354989088476628
        },
        "attn.c_proj": {
          "bits": 6,
          "pruning": 0.055069947535156295
        },
        "mlp.c_fc": {
          "bits": 2,
          "pruning": 0.1434723493435758
        },
        "mlp.c_proj": {
          "bits": 6,
          "pruning": 0.1513210857760437
        }
      },
      "layer_7": {
        "attn.c_attn": {
          "bits": 3,
          "pruning": 0.24273997110348353
        },
        "attn.c_proj": {
          "bits": 3,
          "pruning": 0.18642938472957343
        },
        "mlp.c_fc": {
          "bits": 6,
          "pruning": 0.27127908051388644
        },
        "mlp.c_proj": {
          "bits": 3,
          "pruning": 0.022941196585397325
        }
      },
      "layer_8": {
        "attn.c_attn": {
          "bits": 3,
          "pruning": 0.15036371115753308
        },
        "attn.c_proj": {
          "bits": 6,
          "pruning": 0.24253396505626143
        },
        "mlp.c_fc": {
          "bits": 3,
          "pruning": 0.13260072191659925
        },
        "mlp.c_proj": {
          "bits": 4,
          "pruning": 0.23888597562531153
        }
      },
      "layer_9": {
        "attn.c_attn": {
          "bits": 2,
          "pruning": 0.14754941070901295
        },
        "attn.c_proj": {
          "bits": 3,
          "pruning": 0.022921323916653732
        },
        "mlp.c_fc": {
          "bits": 2,
          "pruning": 0.06399758593644256
        },
        "mlp.c_proj": {
          "bits": 6,
          "pruning": 0.10538662689155526
        }
      },
      "layer_10": {
        "attn.c_attn": {
          "bits": 3,
          "pruning": 0.058424651702090075
        },
        "attn.c_proj": {
          "bits": 6,
          "pruning": 0.24010025771689622
        },
        "mlp.c_fc": {
          "bits": 6,
          "pruning": 0.0435367496844093
        },
        "mlp.c_proj": {
          "bits": 10,
          "pruning": 0.14713021980689167
        }
      },
      "layer_11": {
        "attn.c_attn": {
          "bits": 3,
          "pruning": 0.1149626471769155
        },
        "attn.c_proj": {
          "bits": 3,
          "pruning": 0.13000766979028364
        },
        "mlp.c_fc": {
          "bits": 2,
          "pruning": 0.24189774768248248
        },
        "mlp.c_proj": {
          "bits": 2,
          "pruning": 0.10720381008028891
        }
      }
    }
  }
}