{
  "optimization_summary": {
    "model_name": "gpt2",
    "num_iterations": 50,
    "exploration_weight": 0.2,
    "optimization_time": 940.5832788944244,
    "best_stl_score": 0.09999999855286468,
    "best_model_size": 237.35009765625,
    "best_stl_satisfied": true,
    "best_metrics": {
      "coherence": 0.10000000149011612,
      "attention": 0.19999998807907104,
      "context": 0.15000000596046448,
      "factual": 0.09999999920960936
    },
    "best_robustness": {
      "coherence": 0.10000000149011612,
      "attention": 0.19999998807907104,
      "context": 0.14999991655349731,
      "factual": 0.09999999855286468
    },
    "optimization_history": {
      "iterations": 52,
      "obj_values": [
        76.264990234375,
        -100.88401070536585,
        -100.89111108452441,
        -100.89194358645622,
        -100.871996734068,
        -100.88711961431326,
        -100.89362315415666,
        -100.89617312545265,
        -100.86674078464665,
        -100.89344043640322,
        -100.89993302282579,
        -100.8801004100167,
        -100.89998951776022,
        -100.8805030633312,
        -100.89636153906028,
        -100.89968114267576,
        -100.88257464866312,
        -100.88199721578142,
        -100.89396131565607,
        -100.89999846560377,
        -100.8820463136776,
        -100.89999999972933,
        -100.89072165150262,
        -100.88735438746181,
        -100.88303988406908,
        -100.89072959180531,
        -101.01257574558258,
        -100.89678351722824,
        -100.88330090530204,
        -100.89514963539686,
        -100.89047693567481,
        -100.88463477791784,
        -100.88496364721122,
        -100.89675248746549,
        -100.87402774474445,
        -100.89317762293173,
        -100.88680375687508,
        -100.87983571880784,
        -100.85924895235493,
        -100.89640011925444,
        -100.88118883060513,
        -100.89997311447041,
        -100.89611578445252,
        -100.87073459979949,
        -100.87616153419283,
        -100.8826089721422,
        -101.36452567577362,
        -100.88609218634183,
        -100.89998487665724,
        -100.8957848330941,
        -100.89999988315823,
        -100.89470129025952
      ]
    }
  },
  "best_results": {
    "metrics": {
      "coherence": 0.10000000149011612,
      "attention": 0.19999998807907104,
      "context": 0.15000000596046448,
      "factual": 0.09999999920960936
    },
    "robustness": {
      "coherence": 0.10000000149011612,
      "attention": 0.19999998807907104,
      "context": 0.14999991655349731,
      "factual": 0.09999999855286468
    },
    "stl_score": 0.09999999855286468,
    "stl_satisfied": true,
    "model_size": 237.35009765625,
    "inference_time": 0.00490422248840332,
    "config": {
      "layer_0": {
        "attn.c_attn": {
          "bits": 16,
          "pruning": 0.0
        },
        "attn.c_proj": {
          "bits": 16,
          "pruning": 0.0
        },
        "mlp.c_fc": {
          "bits": 16,
          "pruning": 0.0
        },
        "mlp.c_proj": {
          "bits": 16,
          "pruning": 0.0
        }
      },
      "layer_1": {
        "attn.c_attn": {
          "bits": 16,
          "pruning": 0.0
        },
        "attn.c_proj": {
          "bits": 16,
          "pruning": 0.0
        },
        "mlp.c_fc": {
          "bits": 16,
          "pruning": 0.0
        },
        "mlp.c_proj": {
          "bits": 16,
          "pruning": 0.0
        }
      },
      "layer_2": {
        "attn.c_attn": {
          "bits": 16,
          "pruning": 0.0
        },
        "attn.c_proj": {
          "bits": 16,
          "pruning": 0.0
        },
        "mlp.c_fc": {
          "bits": 16,
          "pruning": 0.0
        },
        "mlp.c_proj": {
          "bits": 16,
          "pruning": 0.0
        }
      },
      "layer_3": {
        "attn.c_attn": {
          "bits": 16,
          "pruning": 0.0
        },
        "attn.c_proj": {
          "bits": 16,
          "pruning": 0.0
        },
        "mlp.c_fc": {
          "bits": 16,
          "pruning": 0.0
        },
        "mlp.c_proj": {
          "bits": 16,
          "pruning": 0.0
        }
      },
      "layer_4": {
        "attn.c_attn": {
          "bits": 16,
          "pruning": 0.0
        },
        "attn.c_proj": {
          "bits": 16,
          "pruning": 0.0
        },
        "mlp.c_fc": {
          "bits": 16,
          "pruning": 0.0
        },
        "mlp.c_proj": {
          "bits": 16,
          "pruning": 0.0
        }
      },
      "layer_5": {
        "attn.c_attn": {
          "bits": 16,
          "pruning": 0.0
        },
        "attn.c_proj": {
          "bits": 16,
          "pruning": 0.0
        },
        "mlp.c_fc": {
          "bits": 16,
          "pruning": 0.0
        },
        "mlp.c_proj": {
          "bits": 16,
          "pruning": 0.0
        }
      },
      "layer_6": {
        "attn.c_attn": {
          "bits": 16,
          "pruning": 0.0
        },
        "attn.c_proj": {
          "bits": 16,
          "pruning": 0.0
        },
        "mlp.c_fc": {
          "bits": 16,
          "pruning": 0.0
        },
        "mlp.c_proj": {
          "bits": 16,
          "pruning": 0.0
        }
      },
      "layer_7": {
        "attn.c_attn": {
          "bits": 16,
          "pruning": 0.0
        },
        "attn.c_proj": {
          "bits": 16,
          "pruning": 0.0
        },
        "mlp.c_fc": {
          "bits": 16,
          "pruning": 0.0
        },
        "mlp.c_proj": {
          "bits": 16,
          "pruning": 0.0
        }
      },
      "layer_8": {
        "attn.c_attn": {
          "bits": 16,
          "pruning": 0.0
        },
        "attn.c_proj": {
          "bits": 16,
          "pruning": 0.0
        },
        "mlp.c_fc": {
          "bits": 16,
          "pruning": 0.0
        },
        "mlp.c_proj": {
          "bits": 16,
          "pruning": 0.0
        }
      },
      "layer_9": {
        "attn.c_attn": {
          "bits": 16,
          "pruning": 0.0
        },
        "attn.c_proj": {
          "bits": 16,
          "pruning": 0.0
        },
        "mlp.c_fc": {
          "bits": 16,
          "pruning": 0.0
        },
        "mlp.c_proj": {
          "bits": 16,
          "pruning": 0.0
        }
      },
      "layer_10": {
        "attn.c_attn": {
          "bits": 16,
          "pruning": 0.0
        },
        "attn.c_proj": {
          "bits": 16,
          "pruning": 0.0
        },
        "mlp.c_fc": {
          "bits": 16,
          "pruning": 0.0
        },
        "mlp.c_proj": {
          "bits": 16,
          "pruning": 0.0
        }
      },
      "layer_11": {
        "attn.c_attn": {
          "bits": 16,
          "pruning": 0.0
        },
        "attn.c_proj": {
          "bits": 16,
          "pruning": 0.0
        },
        "mlp.c_fc": {
          "bits": 16,
          "pruning": 0.0
        },
        "mlp.c_proj": {
          "bits": 16,
          "pruning": 0.0
        }
      }
    }
  }
}